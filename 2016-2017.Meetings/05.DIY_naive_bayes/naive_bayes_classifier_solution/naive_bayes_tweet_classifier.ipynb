{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We'll be applying naive bayes to determine whether a tweet was written by [Donald Trump](https://twitter.com/realDonaldTrump) or [Hillary Clinton](https://twitter.com/HillaryClinton). For a more in-depth theoretical explanation of the theory behind the classifier, see [our notes](https://github.com/MachinesWhoLearn/lectures/blob/master/2016-2017.Meetings/05.DIY_naive_bayes/naive_bayes_primer/naive_bayes_primer.pdf).\n",
    "\n",
    "### Features\n",
    "In our model, the features are the individual words. For example, we'd expect that the word \"wall\" would be more likely to appear in Trump tweets, so we want to account for that in our model. To start off with, we'll load the text data and then perform some basic tokenization to separate out all the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and Counting the Words\n",
    "We want to transform our collection of tweets into something that the model can understand. A basic idea from natural language processing (NLP) is the bag of words approach (BOW). When we use the bag of words, we simply count the number of times a word occurs in a document, and divide it by the total number of words. Doing this for each word, we can get a probability distribution for the probability of a word occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our training data (the raw tweets) and the associated labels (indicating authorship, \"0\" for Hillary and \"1\" for Trump). We'll then count up all the statistics we'll need to use later for calculating probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up some imports and some miscellaneous helper methods we'll be using\n",
    "import re\n",
    "import string\n",
    "from math import log\n",
    "from __future__ import print_function\n",
    "\n",
    "# our default smoothing value, we pretend we see each word at\n",
    "# least once so all our probabilities are well-formed \n",
    "# (so no multiplying by 0 if a word isn't in train set)\n",
    "SMOOTHING = 1.0\n",
    "\n",
    "# location of data file relative to this notebook path\n",
    "TRAIN_DATA_PATH = \"../data/tweets_train.txt\"\n",
    "TRAIN_LABELS_PATH = \"../data/labels_train.txt\"\n",
    "TEST_DATA_PATH = \"../data/tweets_test.txt\"\n",
    "TEST_LABELS_PATH = \"../data/labels_test.txt\"\n",
    "\n",
    "# strip punctuation from a string\n",
    "def remove_punctuation(input_str):\n",
    "    \"from http://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\"\n",
    "    table = string.maketrans(\"\",\"\")\n",
    "    return input_str.translate(table, string.punctuation)\n",
    "\n",
    "# split a line into tokens, or a list of words (known as tokens) \n",
    "# that are separated by whitespace\n",
    "def tokenize(line):\n",
    "    line = remove_punctuation(line)\n",
    "    line = line.lower().strip()\n",
    "    # re.split has an odd tendency to add empty strings, remove those\n",
    "    return [token for token in re.split(\"\\W+\", line) if token != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up some the data structures we'll use to keep track of counts\n",
    "\n",
    "# this dictionary maps the numeric label to the candidate name\n",
    "# the \"\\n\" after each label accounts for the newline character \n",
    "# that follows each one\n",
    "LABEL_MAP = {'0\\n': 'hillary', '1\\n': 'trump'}\n",
    "\n",
    "# this dictionary keeps track of the number of times\n",
    "# word appears in a trump or hillary tweet\n",
    "word_counts_per_candidate = {\n",
    "    \"trump\": {},\n",
    "    \"hillary\": {}\n",
    "}\n",
    "# this dictionary keeps track of how many trump tweets there are and how many\n",
    "# hillary tweets there are. These are our priors!\n",
    "total_tweet_count = {'trump': 0.0, 'hillary': 0.0}\n",
    "\n",
    "# counts words across all tweets\n",
    "vocabulary = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to verify that `tokenize` does what we want it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'growing',\n",
       " 'the',\n",
       " 'republican',\n",
       " 'party',\n",
       " 'tremendously',\n",
       " 'just',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'numbers',\n",
       " 'way',\n",
       " 'up',\n",
       " 'democrats',\n",
       " 'numbers',\n",
       " 'are',\n",
       " 'significantly',\n",
       " 'down',\n",
       " 'from',\n",
       " 'years',\n",
       " 'past']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweet = \"I am growing the Republican Party tremendously - just look at the numbers, way up! Democrats numbers are significantly down from years past.\"\n",
    "sample_tokens = tokenize(sample_tweet)\n",
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the file with train data and refer to it as \"data\", and\n",
    "# open the file with train labels and refer to it as \"labels\"\n",
    "with open(TRAIN_DATA_PATH, 'r') as data, open(TRAIN_LABELS_PATH, 'r') as labels:\n",
    "    # zip data and labels together to create a list of tuples of (tweet,label),\n",
    "    # which we then iterate over. the tweet variable refers to an individual tweet\n",
    "    # and the label variable refers to an individual label\n",
    "    for tweet, label in zip(data, labels):\n",
    "        # if it is a Hillary tweet, increment the \"hillary\" element of `total_tweet_count`\n",
    "        # if it is a Trump tweet, increment the \"trump\" element of `total_tweet_count`.\n",
    "        total_tweet_count[LABEL_MAP[label]] += 1.0\n",
    "        \n",
    "        tokens = tokenize(tweet)\n",
    "        \n",
    "        # iterate over the words we found in the tweet\n",
    "        for word in tokens:\n",
    "            # if we haven't seen a word yet, let's add it to our dictionary with a \n",
    "            # count of 2 * how much we smoothing up by (`SMOOTHING`),\n",
    "            # (since we presume that both hillary and trump have seen it)\n",
    "            # we'll be incrementing it later\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = 4 * SMOOTHING\n",
    "                # similarily, since we pretend that we saw an extra tweet \n",
    "                # with this unknown word and one without, we add 2*SMOOTHING\n",
    "                # to hillary and trump\n",
    "                total_tweet_count[\"trump\"] += 2*SMOOTHING\n",
    "                total_tweet_count[\"hillary\"] += 2*SMOOTHING\n",
    "                word_counts_per_candidate[\"trump\"][word] = 1\n",
    "                word_counts_per_candidate[\"hillary\"][word] = 1\n",
    "            # now add one to the global dictionary\n",
    "            # and the associated candidate's\n",
    "            # dictionary\n",
    "            vocabulary[word] += 1\n",
    "            word_counts_per_candidate[LABEL_MAP[label]][word] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our output / a bit of our output for the long dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hillary': 16812.0, 'trump': 16770.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 5.0,\n",
       " 'eligible': 5.0,\n",
       " 'foul': 5.0,\n",
       " 'four': 29.0,\n",
       " 'igual': 5.0,\n",
       " 'looking': 39.0,\n",
       " 'lord': 5.0,\n",
       " 'plaudits': 5.0,\n",
       " 'railing': 6.0,\n",
       " 'rawlingsblake': 5.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_vocabulary = {k: vocabulary[k] for k in vocabulary.keys()[:10]}\n",
    "first_10_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 1,\n",
       " 'eligible': 2,\n",
       " 'foul': 1,\n",
       " 'four': 11,\n",
       " 'igual': 2,\n",
       " 'looking': 7,\n",
       " 'lord': 1,\n",
       " 'plaudits': 1,\n",
       " 'railing': 2,\n",
       " 'rawlingsblake': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_counts_per_candidate_H = {k: word_counts_per_candidate[\"hillary\"][k] for k in word_counts_per_candidate[\"hillary\"].keys()[:10]}\n",
    "first_10_word_counts_per_candidate_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 2,\n",
       " 'eligible': 1,\n",
       " 'foul': 2,\n",
       " 'four': 16,\n",
       " 'igual': 1,\n",
       " 'looking': 30,\n",
       " 'lord': 2,\n",
       " 'plaudits': 2,\n",
       " 'railing': 2,\n",
       " 'rawlingsblake': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_counts_per_candidate_T = {k: word_counts_per_candidate[\"trump\"][k] for k in word_counts_per_candidate[\"trump\"].keys()[:10]}\n",
    "first_10_word_counts_per_candidate_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Conditional Probabilities\n",
    "Now, we'll proceed to calculate the the conditional probabilities for each word; that is, we want to know $\\mathbb{P}(word|candidate)$, for each candidate. More verbosely, we will be calculating $\\mathbb{P}(word|H)$ and $\\mathbb{P}(word|T)$ for each in our vocabulary and for each event $H$ and $T$ (where $H$ is the event that Hillary Clinton is the author, and $T$ is the event that Donald Trump is the author)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_probabilities_per_candidate = {\n",
    "    \"trump\": {},\n",
    "    \"hillary\": {}\n",
    "}\n",
    "\n",
    "# iterate over the hillary and trump dictionaries within \n",
    "# `word_count_per_candidate` with this outside loop\n",
    "for candidate in word_counts_per_candidate:\n",
    "    for word, count in word_counts_per_candidate[candidate].items():\n",
    "        word_probabilities_per_candidate[candidate][word] = count / total_tweet_count[candidate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at our calculated probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 5.948132286462051e-05,\n",
       " 'eligible': 0.00011896264572924102,\n",
       " 'foul': 5.948132286462051e-05,\n",
       " 'four': 0.0006542945515108256,\n",
       " 'goodpaying': 0.00035688793718772306,\n",
       " 'igual': 0.00011896264572924102,\n",
       " 'looking': 0.0004163692600523436,\n",
       " 'lord': 5.948132286462051e-05,\n",
       " 'plaudits': 5.948132286462051e-05,\n",
       " 'railing': 0.00011896264572924102}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_probabilities_per_candidate_H = {k: word_probabilities_per_candidate[\"hillary\"][k] for k in word_probabilities_per_candidate[\"hillary\"].keys()[:10]}\n",
    "first_10_word_probabilities_per_candidate_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 0.00011926058437686345,\n",
       " 'eligible': 5.9630292188431724e-05,\n",
       " 'foul': 0.00011926058437686345,\n",
       " 'four': 0.0009540846750149076,\n",
       " 'goodpaying': 5.9630292188431724e-05,\n",
       " 'igual': 5.9630292188431724e-05,\n",
       " 'looking': 0.0017889087656529517,\n",
       " 'lord': 0.00011926058437686345,\n",
       " 'plaudits': 0.00011926058437686345,\n",
       " 'railing': 0.00011926058437686345}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_probabilities_per_candidate_T = {k: word_probabilities_per_candidate[\"trump\"][k] for k in word_probabilities_per_candidate[\"trump\"].keys()[:10]}\n",
    "first_10_word_probabilities_per_candidate_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Classifier\n",
    "In this problem, the posterior probability of a tweet, represented as a set of words $(x_1, \\dots, x_n)$, being written by Hillary is defined with Bayes' rule as: $$\\mathbb{P}(H|x_1, \\dots, x_n) \\approx \\frac{\\mathbb{P}(H)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H)}{\\mathbb{P}(H)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H) + \\mathbb{P}(T)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | T)}$$\n",
    "\n",
    "We now have all the tools we need to calculate this posterior probability of a tweet being written by Hillary Clinton or Donald Trump. We'll walk through what everything represents step by step.\n",
    "\n",
    "$\\mathbb{P}(H)$ is the prior probability of a tweet being written by Hillary, which is calculated with $\\frac{\\# of Hillary tweets}{\\# of total tweets}$. This information is in the `total_tweet_count` dictionary. Similarly, we can calculate $\\mathbb{P}(T)$, the prior probability of a tweet being written by Trump, which is $\\frac{\\# of Trump tweets}{\\# of total tweets}$.\n",
    "\n",
    "$\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H)$ is the product of the conditional probabilities for each word $\\mathbb{P}(x_i | H)$. We've calculated $\\mathbb{P}(x_i | H)$ for each word in the dictionary `word_probabilities_per_candidate`, so we can simply multiply them together to get their product. We take a similar approach with $\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | T)$.\n",
    "\n",
    "\n",
    "## Log-Probabilities\n",
    "Since we're multiplying many small values together, we run the risk of floating-point underflow. We solve this, in short, by turning $a \\times b$ into $log(a) + log(b)$. Since converting the probabilities to log values does nothing to their ordering (if $\\mathbb{P}(A) > \\mathbb{P}(B)$, then $log(\\mathbb{P}(A)) > log(\\mathbb{P}(B)$)). In this way, we avoid arithmetic underflow while keeping the well-ordering of the probabilities, which is all we need for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new counter to keep track of how many we classified correctly\n",
    "# and incorrectly. tuples are arranged (our guess, correct label)\n",
    "outcomes = {(\"trump\", \"trump\"): 0.0,\n",
    "            (\"trump\", \"hillary\"): 0.0,\n",
    "            (\"hillary\", \"hillary\"): 0.0,\n",
    "            (\"hillary\", \"trump\"): 0.0\n",
    "           }\n",
    "\n",
    "# calculate our priors and take the log\n",
    "prior_trump = total_tweet_count['trump'] / sum(total_tweet_count.values())\n",
    "prior_hillary = total_tweet_count['hillary'] / sum(total_tweet_count.values())\n",
    "log_prior_trump = log(prior_trump)\n",
    "log_prior_hillary = log(prior_hillary)\n",
    "\n",
    "# open the test data and test labels and refer to them as \"test_data\" and \"test_labels\", respectively\n",
    "with open(TEST_DATA_PATH, 'r') as test_data, open(TEST_LABELS_PATH, 'r') as test_labels:\n",
    "    # zip `test_data` and `test_labels` together to create a list of tuples of (tweet,label),\n",
    "    # which we then iterate over. the `tweet` variable refers to an individual tweet\n",
    "    # and the `label` variable refers to an individual label\n",
    "    for test_tweet, test_label in zip(test_data, test_labels):\n",
    "        # turn the test tweet into tokens\n",
    "        test_tokens = tokenize(test_tweet)\n",
    "        log_p_tweet_given_trump = 0.0\n",
    "        log_p_tweet_given_hillary = 0.0\n",
    "        for token in test_tokens:\n",
    "            if token in vocabulary:\n",
    "                p_word_given_trump = word_probabilities_per_candidate['trump'][token]\n",
    "                log_p_word_given_trump = log(p_word_given_trump)\n",
    "                # remember adding two logs is like multiplying their raw values\n",
    "                log_p_tweet_given_trump += log_p_word_given_trump\n",
    "\n",
    "                p_word_given_hillary = word_probabilities_per_candidate['hillary'][token]\n",
    "                log_p_word_given_hillary = log(p_word_given_hillary)\n",
    "                log_p_tweet_given_hillary += log_p_word_given_hillary\n",
    "            else:\n",
    "                # note that the token isn't in word_probabilities (and thus \n",
    "                # isn't seen in our train set), then we just ignore it\n",
    "                # this works fine for this model, but there are a variety of NLP techniques\n",
    "                # one could apply to handle \"unknown tokens\". Feel \n",
    "                # free to ask if you want details!\n",
    "                pass\n",
    "            \n",
    "        # note that we don't actually have to do this, but it's here for didactic purposes\n",
    "        # we can directly compare `log_p_tweet_given_hillary` with `log_p_tweet_given_trump`\n",
    "        # to figure out which posterior probability will be greater!\n",
    "        p_hillary_given_tweet_denominator = ((log_prior_hillary+log_p_tweet_given_hillary) + \n",
    "                                             (log_prior_trump+log_p_tweet_given_trump))\n",
    "        # division is subtraction in logspace\n",
    "        p_hillary_given_tweet = (log_prior_hillary+log_p_tweet_given_hillary) - p_hillary_given_tweet_denominator\n",
    "        \n",
    "        p_trump_given_tweet_denominator = ((log_prior_hillary+log_p_tweet_given_hillary) + \n",
    "                                           (log_prior_trump+log_p_tweet_given_trump))\n",
    "        # division is subtraction in logspace\n",
    "        p_trump_given_tweet = (log_prior_trump+log_p_tweet_given_trump) - p_trump_given_tweet_denominator\n",
    "        \n",
    "        # echoing what was said above, we could simply compare log_prior_trump+log_p_tweet_given_trump with\n",
    "        # log_prior_hillary+log_p_tweet_given_hillary, since notice that the values of the denominators\n",
    "        # in both cases for the full posterior probability is the same! thus, if you want to \n",
    "        # merely find out which is larger, you can just compare the numerators.\n",
    "        if p_trump_given_tweet >= p_hillary_given_tweet:\n",
    "            # probability that trump wrote the tweet is higher, \n",
    "            # so we predict trump. Write our prediction\n",
    "            # and the correct label to the dictionary\n",
    "            outcomes[(\"trump\", LABEL_MAP[test_label])] += 1\n",
    "        else:\n",
    "            # probability that trump wrote the tweet is higher, \n",
    "            # so we predict trump. Write our prediction\n",
    "            # and the correct label to the dictionary\n",
    "            outcomes[('hillary', LABEL_MAP[test_label])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('hillary', 'hillary'): 756.0,\n",
       " ('hillary', 'trump'): 150.0,\n",
       " ('trump', 'hillary'): 43.0,\n",
       " ('trump', 'trump'): 640.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing `Outcomes`\n",
    "We see that we predicted \"hillary\" correctly 756 times, and predicted \"trump\" correctly 640 times. However, we made a fair amount of errors as well; confusing \"trump\" for \"hillary\" 150 times and vice versa 43 times.\n",
    "\n",
    "Let's calculate our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.87853996224\n"
     ]
    }
   ],
   "source": [
    "accuracy = (outcomes[(\"hillary\", \"hillary\")] + outcomes[(\"trump\", \"trump\")]) / sum(outcomes.values())\n",
    "\n",
    "print(\"accuracy: {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mwl]",
   "language": "python",
   "name": "conda-env-mwl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
