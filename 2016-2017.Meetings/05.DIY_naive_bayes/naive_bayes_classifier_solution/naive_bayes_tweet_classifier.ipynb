{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We'll be applying naive bayes to determine whether a tweet was written by [Donald Trump](https://twitter.com/realDonaldTrump) or [Hillary Clinton](https://twitter.com/HillaryClinton). For a more in-depth theoretical explanation of the theory behind the classifier, see [our notes](https://github.com/MachinesWhoLearn/lectures/blob/master/2016-2017.Meetings/05.DIY_naive_bayes/naive_bayes_primer/naive_bayes_primer.pdf).\n",
    "\n",
    "Note: GitHub has some issues with rendering latex in ipython notebooks, so download the notebook and run it locally yourself if you want to see all the equations.\n",
    "\n",
    "### Features\n",
    "In our model, the features are the individual words. For example, we'd expect that the word \"wall\" would be more likely to appear in Trump tweets, so we want to account for that in our model. To start off with, we'll load the text data and then perform some basic tokenization to separate out all the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and Counting the Words\n",
    "We want to transform our collection of tweets into something that the model can understand. A basic idea from natural language processing (NLP) is the bag of words approach (BOW). When we use the bag of words, we simply count the number of times a word occurs in a document, and divide it by the total number of words. Doing this for each word, we can get a probability distribution for the probability of a word occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our training data (the raw tweets) and the associated labels (indicating authorship, \"0\" for Hillary and \"1\" for Trump). We'll then count up all the statistics we'll need to use later for calculating probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up some imports and some miscellaneous helper methods we'll be using\n",
    "import re\n",
    "import string\n",
    "from math import log\n",
    "from __future__ import print_function\n",
    "\n",
    "# our default smoothing value, we pretend we see each word at\n",
    "# least once so all our probabilities are well-formed \n",
    "# (so no multiplying by 0 if a word isn't in train set)\n",
    "SMOOTHING = 1.0\n",
    "\n",
    "# location of data file relative to this notebook path\n",
    "TRAIN_DATA_PATH = \"../data/tweets_train.txt\"\n",
    "TRAIN_LABELS_PATH = \"../data/labels_train.txt\"\n",
    "TEST_DATA_PATH = \"../data/tweets_test.txt\"\n",
    "TEST_LABELS_PATH = \"../data/labels_test.txt\"\n",
    "\n",
    "# strip punctuation from a string\n",
    "def remove_punctuation(input_str):\n",
    "    # from http://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\n",
    "    table = string.maketrans(\"\",\"\")\n",
    "    return input_str.translate(table, string.punctuation)\n",
    "\n",
    "# split a line into tokens, or a list of words (known as tokens) \n",
    "# that are separated by whitespace\n",
    "def tokenize(line):\n",
    "    line = remove_punctuation(line)\n",
    "    line = line.lower().strip()\n",
    "    # re.split has an odd tendency to add empty strings, remove those\n",
    "    return [token for token in re.split(\"\\W+\", line) if token != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up some the data structures we'll use to keep track of counts\n",
    "\n",
    "# this dictionary maps the numeric label to the candidate name\n",
    "# the \"\\n\" after each label accounts for the newline character \n",
    "# that follows each one\n",
    "LABEL_MAP = {'0\\n': 'hillary', '1\\n': 'trump'}\n",
    "\n",
    "# this dictionary keeps track of the number of times\n",
    "# a word appears in a trump or hillary tweet\n",
    "word_counts_per_candidate = {\n",
    "    \"trump\": {},\n",
    "    \"hillary\": {}\n",
    "}\n",
    "# this dictionary keeps track of how many trump tweets there are and how many\n",
    "# hillary tweets there are. These are our priors.\n",
    "total_tweet_count = {'trump': 0.0, 'hillary': 0.0}\n",
    "\n",
    "# counts words across all tweets\n",
    "vocabulary = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to verify that `tokenize` does what we want it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'growing',\n",
       " 'the',\n",
       " 'republican',\n",
       " 'party',\n",
       " 'tremendously',\n",
       " 'just',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'numbers',\n",
       " 'way',\n",
       " 'up',\n",
       " 'democrats',\n",
       " 'numbers',\n",
       " 'are',\n",
       " 'significantly',\n",
       " 'down',\n",
       " 'from',\n",
       " 'years',\n",
       " 'past']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweet = \"I am growing the Republican Party tremendously - just look at the numbers, way up! Democrats numbers are significantly down from years past.\"\n",
    "sample_tokens = tokenize(sample_tweet)\n",
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the file with train data and refer to it as \"data\", and\n",
    "# open the file with train labels and refer to it as \"labels\"\n",
    "with open(TRAIN_DATA_PATH, 'r') as data, open(TRAIN_LABELS_PATH, 'r') as labels:\n",
    "    # zip data and labels together to create a list of tuples of (tweet,label),\n",
    "    # which we then iterate over. the tweet variable refers to an individual tweet\n",
    "    # and the label variable refers to an individual label\n",
    "    for tweet, label in zip(data, labels):\n",
    "        # if it is a Hillary tweet, increment the \"hillary\" element of `total_tweet_count`\n",
    "        # if it is a Trump tweet, increment the \"trump\" element of `total_tweet_count`.\n",
    "        total_tweet_count[LABEL_MAP[label]] += 1.0\n",
    "        \n",
    "        tokens = tokenize(tweet)\n",
    "        \n",
    "        # iterate over the words we found in the tweet\n",
    "        for word in tokens:\n",
    "            # if we haven't seen a word yet, let's add it to our dictionary with a \n",
    "            # count of 2 * how much we smoothing up by (`SMOOTHING`),\n",
    "            # (since we presume that both hillary and trump have seen it)\n",
    "            \n",
    "            # we essentially pretend that there is a tweet in the hillary\n",
    "            # and trump train sets that contain ALL of the words in the vocabulary\n",
    "            # and a tweet that contains NONE of the words in the vocabulary.\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = 2 * SMOOTHING\n",
    "                # similarily, since we pretend that we saw an extra tweet \n",
    "                # with this unknown word and one without, we add SMOOTHING\n",
    "                # to hillary and trump.\n",
    "                word_counts_per_candidate[\"trump\"][word] = SMOOTHING\n",
    "                word_counts_per_candidate[\"hillary\"][word] = SMOOTHING\n",
    "            # now add one to the global dictionary\n",
    "            # and the associated candidate's\n",
    "            # dictionary\n",
    "            vocabulary[word] += 1\n",
    "            word_counts_per_candidate[LABEL_MAP[label]][word] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our output / a bit of our output for the long dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hillary': 2404.0, 'trump': 2362.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tweet_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of `total_tweet_count`, we know that there are 2404 \"hillary\" tweets in our train set and 2362 \"trump\" tweets in our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 3.0,\n",
       " 'eligible': 3.0,\n",
       " 'foul': 3.0,\n",
       " 'four': 27.0,\n",
       " 'igual': 3.0,\n",
       " 'looking': 37.0,\n",
       " 'lord': 3.0,\n",
       " 'plaudits': 3.0,\n",
       " 'railing': 4.0,\n",
       " 'rawlingsblake': 3.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_vocabulary = {k: vocabulary[k] for k in vocabulary.keys()[:10]}\n",
    "first_10_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the first 10 items of the `vocabulary` dictionary shows that \"electricity\" was used 3 times across all tweets, \"elegible\" and \"foul\" 3 times as well, \"four\" 27 times, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 1.0,\n",
       " 'eligible': 2.0,\n",
       " 'foul': 1.0,\n",
       " 'four': 11.0,\n",
       " 'igual': 2.0,\n",
       " 'looking': 7.0,\n",
       " 'lord': 1.0,\n",
       " 'plaudits': 1.0,\n",
       " 'railing': 2.0,\n",
       " 'rawlingsblake': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_counts_per_candidate_H = {k: word_counts_per_candidate[\"hillary\"][k] for k in word_counts_per_candidate[\"hillary\"].keys()[:10]}\n",
    "first_10_word_counts_per_candidate_H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the first 10 items of the inner dictionary of `word_counts_per_candidate` referring to \"hillary\" (`word_counts_per_candidate[hillary]`) shows that \"electricity\" was used 1 time across all tweets, \"elegible\" 2 times, \"foul\" 1 time, \"four\" 11 times, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 2.0,\n",
       " 'eligible': 1.0,\n",
       " 'foul': 2.0,\n",
       " 'four': 16.0,\n",
       " 'igual': 1.0,\n",
       " 'looking': 30.0,\n",
       " 'lord': 2.0,\n",
       " 'plaudits': 2.0,\n",
       " 'railing': 2.0,\n",
       " 'rawlingsblake': 2.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_counts_per_candidate_T = {k: word_counts_per_candidate[\"trump\"][k] for k in word_counts_per_candidate[\"trump\"].keys()[:10]}\n",
    "first_10_word_counts_per_candidate_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the first 10 items of the inner dictionary of `word_counts_per_candidate` referring to \"trump\" (`word_counts_per_candidate[trump]`) shows that \"electricity\" was used 2 times across all tweets, \"elegible\" 1 time, \"foul\" 2 times, \"four\" 16 times, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Conditional Probabilities\n",
    "Now, we'll proceed to calculate the the conditional probabilities for each word; that is, we want to know $\\mathbb{P}(word|candidate)$, for each word in our vocabulary and each candidate we are trying to classify between. \n",
    "\n",
    "More concretely, we will be calculating $\\mathbb{P}(word|H)$ and $\\mathbb{P}(word|T)$ for each in our vocabulary and for each event $H$ and $T$ (where $H$ is the event that Hillary Clinton is the author, and $T$ is the event that Donald Trump is the author)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_probabilities_per_candidate = {\n",
    "    \"trump\": {},\n",
    "    \"hillary\": {}\n",
    "}\n",
    "\n",
    "# iterate over the hillary and trump dictionaries within \n",
    "# `word_count_per_candidate` with this outside loop\n",
    "for candidate in word_counts_per_candidate:\n",
    "    for word, count in word_counts_per_candidate[candidate].items():\n",
    "        # add two to the denominator due to smoothing!\n",
    "        word_probabilities_per_candidate[candidate][word] = count / (total_tweet_count[candidate]+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some of our calculated word probabilities for each candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 0.00041562759767248546,\n",
       " 'eligible': 0.0008312551953449709,\n",
       " 'foul': 0.00041562759767248546,\n",
       " 'four': 0.00457190357439734,\n",
       " 'goodpaying': 0.0024937655860349127,\n",
       " 'igual': 0.0008312551953449709,\n",
       " 'looking': 0.0029093931837073984,\n",
       " 'lord': 0.00041562759767248546,\n",
       " 'plaudits': 0.00041562759767248546,\n",
       " 'railing': 0.0008312551953449709}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_probabilities_per_candidate_H = {k: word_probabilities_per_candidate[\"hillary\"][k] for k in word_probabilities_per_candidate[\"hillary\"].keys()[:10]}\n",
    "first_10_word_probabilities_per_candidate_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electricity': 0.0008460236886632825,\n",
       " 'eligible': 0.00042301184433164127,\n",
       " 'foul': 0.0008460236886632825,\n",
       " 'four': 0.00676818950930626,\n",
       " 'goodpaying': 0.00042301184433164127,\n",
       " 'igual': 0.00042301184433164127,\n",
       " 'looking': 0.012690355329949238,\n",
       " 'lord': 0.0008460236886632825,\n",
       " 'plaudits': 0.0008460236886632825,\n",
       " 'railing': 0.0008460236886632825}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_word_probabilities_per_candidate_T = {k: word_probabilities_per_candidate[\"trump\"][k] for k in word_probabilities_per_candidate[\"trump\"].keys()[:10]}\n",
    "first_10_word_probabilities_per_candidate_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Classifier\n",
    "In this problem, the posterior probability of a tweet, represented as a set of words $(x_1, \\dots, x_n)$, being written by Hillary is defined with Bayes' rule as: $$\\mathbb{P}(H|x_1, \\dots, x_n) \\approx \\frac{\\mathbb{P}(H)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H)}{\\mathbb{P}(H)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H) + \\mathbb{P}(T)\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | T)}$$\n",
    "\n",
    "We now have all the tools we need to calculate this posterior probability of a tweet being written by Hillary Clinton or Donald Trump. We'll walk through what everything represents step by step.\n",
    "\n",
    "$\\mathbb{P}(H)$ is the prior probability of a tweet being written by Hillary, which is calculated with $\\frac{\\# of Hillary tweets}{\\# of total tweets}$. This information is in the `total_tweet_count` dictionary. Similarly, we can calculate $\\mathbb{P}(T)$, the prior probability of a tweet being written by Trump, which is $\\frac{\\# of Trump tweets}{\\# of total tweets}$.\n",
    "\n",
    "$\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | H)$ is the product of the conditional probabilities for each word $\\mathbb{P}(x_i | H)$. We've calculated $\\mathbb{P}(x_i | H)$ for each word in the dictionary `word_probabilities_per_candidate`, so we can simply multiply them together to get their product. We take a similar approach with $\\prod\\limits_{i=1}^n \\mathbb{P}(x_i | T)$.\n",
    "\n",
    "\n",
    "## Log-Probabilities\n",
    "Since we're multiplying many small values together, we run the risk of floating-point underflow. We solve this, in short, by turning $a \\times b$ into $log(a) + log(b)$. Since converting the probabilities to log values does nothing to their ordering (if $\\mathbb{P}(A) > \\mathbb{P}(B)$, then $log(\\mathbb{P}(A)) > log(\\mathbb{P}(B)$)). In this way, we avoid arithmetic underflow while keeping the well-ordering of the probabilities, which is all we need for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new counter to keep track of how many we classified correctly\n",
    "# and incorrectly. tuples are arranged (our guess, correct label)\n",
    "outcomes = {(\"trump\", \"trump\"): 0.0,\n",
    "            (\"trump\", \"hillary\"): 0.0,\n",
    "            (\"hillary\", \"hillary\"): 0.0,\n",
    "            (\"hillary\", \"trump\"): 0.0\n",
    "           }\n",
    "\n",
    "# calculate our priors and take the log\n",
    "prior_trump = total_tweet_count['trump'] / sum(total_tweet_count.values())\n",
    "prior_hillary = total_tweet_count['hillary'] / sum(total_tweet_count.values())\n",
    "log_prior_trump = log(prior_trump)\n",
    "log_prior_hillary = log(prior_hillary)\n",
    "\n",
    "# open the test data and test labels and refer to them as \"test_data\" and \"test_labels\", respectively\n",
    "with open(TEST_DATA_PATH, 'r') as test_data, open(TEST_LABELS_PATH, 'r') as test_labels:\n",
    "    # zip `test_data` and `test_labels` together to create a list of tuples of (tweet,label),\n",
    "    # which we then iterate over. the `tweet` variable refers to an individual tweet\n",
    "    # and the `label` variable refers to an individual label\n",
    "    for test_tweet, test_label in zip(test_data, test_labels):\n",
    "        # turn the test tweet into tokens\n",
    "        test_tokens = tokenize(test_tweet)\n",
    "        log_p_tweet_given_trump = 0.0\n",
    "        log_p_tweet_given_hillary = 0.0\n",
    "        for token in test_tokens:\n",
    "            if token in vocabulary:\n",
    "                p_word_given_trump = word_probabilities_per_candidate['trump'][token]\n",
    "                log_p_word_given_trump = log(p_word_given_trump)\n",
    "                # remember adding two logs is like multiplying their raw values\n",
    "                log_p_tweet_given_trump += log_p_word_given_trump\n",
    "\n",
    "                p_word_given_hillary = word_probabilities_per_candidate['hillary'][token]\n",
    "                log_p_word_given_hillary = log(p_word_given_hillary)\n",
    "                log_p_tweet_given_hillary += log_p_word_given_hillary\n",
    "            else:\n",
    "                # note that the token isn't in word_probabilities (and thus \n",
    "                # isn't seen in our train set), then we just ignore it\n",
    "                # this works fine for this model, but there are a variety of NLP techniques\n",
    "                # one could apply to handle \"unknown tokens\". Feel \n",
    "                # free to ask if you want details!\n",
    "                pass\n",
    "            \n",
    "        # note that we don't actually have to do these next few lines, but it's here for didactic purposes\n",
    "        # we can directly compare `log_p_tweet_given_hillary` with `log_p_tweet_given_trump`\n",
    "        # to figure out which posterior probability will be greater!\n",
    "        p_hillary_given_tweet_denominator = ((log_prior_hillary+log_p_tweet_given_hillary) + \n",
    "                                             (log_prior_trump+log_p_tweet_given_trump))\n",
    "        # division is subtraction in logspace\n",
    "        p_hillary_given_tweet = (log_prior_hillary+log_p_tweet_given_hillary) - p_hillary_given_tweet_denominator\n",
    "        \n",
    "        p_trump_given_tweet_denominator = ((log_prior_hillary+log_p_tweet_given_hillary) + \n",
    "                                           (log_prior_trump+log_p_tweet_given_trump))\n",
    "        # division is subtraction in logspace\n",
    "        p_trump_given_tweet = (log_prior_trump+log_p_tweet_given_trump) - p_trump_given_tweet_denominator\n",
    "        \n",
    "        # echoing what was said above, we could simply compare log_prior_trump+log_p_tweet_given_trump with\n",
    "        # log_prior_hillary+log_p_tweet_given_hillary, since notice that the values of the denominators\n",
    "        # in both cases for the full posterior probability is the same! thus, if you want to \n",
    "        # merely find out which is larger, you can just compare the numerators.\n",
    "        if p_trump_given_tweet >= p_hillary_given_tweet:\n",
    "            # probability that trump wrote the tweet is higher, \n",
    "            # so we predict trump. Write our prediction\n",
    "            # and the correct label to the dictionary\n",
    "            outcomes[(\"trump\", LABEL_MAP[test_label])] += 1\n",
    "        else:\n",
    "            # probability that trump wrote the tweet is higher, \n",
    "            # so we predict trump. Write our prediction\n",
    "            # and the correct label to the dictionary\n",
    "            outcomes[('hillary', LABEL_MAP[test_label])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('hillary', 'hillary'): 755.0,\n",
       " ('hillary', 'trump'): 142.0,\n",
       " ('trump', 'hillary'): 44.0,\n",
       " ('trump', 'trump'): 648.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing `Outcomes`\n",
    "We see that we predicted \"hillary\" correctly 755 times, and predicted \"trump\" correctly 648 times. However, we made a fair amount of errors as well; confusing \"trump\" for \"hillary\" 142 times and vice versa 44 times.\n",
    "\n",
    "Let's calculate our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.882945248584\n"
     ]
    }
   ],
   "source": [
    "accuracy = (outcomes[(\"hillary\", \"hillary\")] + outcomes[(\"trump\", \"trump\")]) / sum(outcomes.values())\n",
    "\n",
    "print(\"accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes did pretty well for such a seemingly simple method! Additionally, since the only computation required is counting, `log`, and arithmetic, it's quite fast as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mwl]",
   "language": "python",
   "name": "conda-env-mwl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
