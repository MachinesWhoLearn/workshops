{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook, we want to build a logistic regression classifier in Tensorflow for MNIST.\n",
    "\n",
    "The logistic regression classifier is defined as: $y = sigmoid(Wx + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Read in the data into the \"/data/mnist\" folder\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Create placeholders to feed your inputs and labels into\n",
    "# Each MNIST image has 28*28 = 784 pixels. So you can represent it as a 1x784 Tensor.\n",
    "# There are 10 possible classes for each image, corresponding to digits 0-9.\n",
    "# Name the input placeholder mnist_inputs and the labels placeholder mnist_labels\n",
    "mnist_inputs = tf.placeholder(\"float\", [None, 784], name=\"mnist_inputs_placeholder\") \n",
    "mnist_labels = tf.placeholder(\"float\", [None, 10], name='mnist_labels_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Create Variables for the parameters of the model: the weights and the bias.\n",
    "# Initialize the bias to a 0 tensor. (hint: tf.zeros)\n",
    "# Initialize the weights with a random uniform distribution, with a max of 1 and a min of -1. (hint: tf.random_uniform)\n",
    "# Be sure to think carefully about the shapes of these tensors.\n",
    "W = tf.Variable(tf.random_uniform([784, 10], -1, 1), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros(shape=[1, 10]), name=\"bias\")\n",
    "\n",
    "# Optional: Define a global_step variable for use in tensorboard\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Build the model, stringing together your placeholders and variables to create\n",
    "# two ops: one for the logits (output right before sigmoid), and one for the probability\n",
    "# distribution generated from the model (output right after sigmoid/softmax operation).\n",
    "# tf.nn.softmax may come in handy for generating the probabilities.\n",
    "\n",
    "# Name the logits operation \"logits\", and the probability operation \"predictions\".\n",
    "with tf.name_scope(\"model\"):\n",
    "    logits = tf.matmul(mnist_inputs, W) + b\n",
    "    predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Define your loss function. Use the cross entropy loss function, and use tensorflow's\n",
    "# built in \"tf.nn.sofmtax_cross_entropy_with_logits(logits, labels)\" function to get the xentropy\n",
    "# of each instance in the batch. Then, get the average loss of the batch.\n",
    "# Name the loss op \"loss\"\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=mnist_labels, name=\"xentropy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Define a function to get the accuracy of your model on this batch. Name it \"accuracy\"\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_preds = tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist_labels, 1))\n",
    "    num_correct_preds = tf.reduce_sum(tf.cast(correct_preds, \"float\"))\n",
    "    accuracy = num_correct_preds / tf.cast(tf.shape(mnist_inputs)[0], \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 6: Define an optimizer that you want to use, and create the training operation to \n",
    "# use the optimizer to minimize the loss. Name the training operation \"train_op\"\n",
    "with tf.name_scope(\"train_op\"):\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define summary ops for TensorBoard (optional). Name the summary op \"summary_op\".\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 done! Average Train Loss: 3.4256333865398583, Average Train Accuracy: 0.3581031976744186\n",
      "Epoch 1 done! Average Train Loss: 1.0017955978249395, Average Train Accuracy: 0.7183321220930232\n",
      "Epoch 2 done! Average Train Loss: 0.6738615992457367, Average Train Accuracy: 0.8082303779069767\n",
      "Epoch 3 done! Average Train Loss: 0.548311646248019, Average Train Accuracy: 0.8456213662790698\n",
      "Epoch 4 done! Average Train Loss: 0.4821911367219548, Average Train Accuracy: 0.8640261627906977\n",
      "Epoch 5 done! Average Train Loss: 0.4398189597005068, Average Train Accuracy: 0.877234738372093\n",
      "Epoch 6 done! Average Train Loss: 0.4083902920747912, Average Train Accuracy: 0.8861555232558139\n",
      "Epoch 7 done! Average Train Loss: 0.38565764475700465, Average Train Accuracy: 0.8916424418604652\n",
      "Epoch 8 done! Average Train Loss: 0.3688659559502158, Average Train Accuracy: 0.8971838662790698\n",
      "Epoch 9 done! Average Train Loss: 0.35390536715818005, Average Train Accuracy: 0.9012172965116279\n",
      "Epoch 10 done! Average Train Loss: 0.3435074862352637, Average Train Accuracy: 0.9039244186046511\n",
      "Epoch 11 done! Average Train Loss: 0.33216015826477563, Average Train Accuracy: 0.9067950581395349\n",
      "Epoch 12 done! Average Train Loss: 0.3238261203953, Average Train Accuracy: 0.909265988372093\n",
      "Epoch 13 done! Average Train Loss: 0.31899610969216324, Average Train Accuracy: 0.9110646802325582\n",
      "Epoch 14 done! Average Train Loss: 0.3095394967253818, Average Train Accuracy: 0.9140806686046512\n",
      "Epoch 15 done! Average Train Loss: 0.30560091661159383, Average Train Accuracy: 0.9144622093023256\n",
      "Epoch 16 done! Average Train Loss: 0.2990563698286234, Average Train Accuracy: 0.9163154069767442\n",
      "Epoch 17 done! Average Train Loss: 0.2963090715366741, Average Train Accuracy: 0.9175145348837209\n",
      "Epoch 18 done! Average Train Loss: 0.2911365210490171, Average Train Accuracy: 0.9200581395348837\n",
      "Epoch 19 done! Average Train Loss: 0.2862828870325588, Average Train Accuracy: 0.9195857558139535\n",
      "Epoch 20 done! Average Train Loss: 0.2853612653391306, Average Train Accuracy: 0.9211300872093023\n",
      "Epoch 21 done! Average Train Loss: 0.28377954462586447, Average Train Accuracy: 0.9210210755813953\n",
      "Epoch 22 done! Average Train Loss: 0.2793030460213506, Average Train Accuracy: 0.9227107558139535\n",
      "Epoch 23 done! Average Train Loss: 0.27408978724202443, Average Train Accuracy: 0.9228924418604652\n",
      "Epoch 24 done! Average Train Loss: 0.2745861433792946, Average Train Accuracy: 0.9237100290697674\n",
      "Epoch 25 done! Average Train Loss: 0.27047092256157895, Average Train Accuracy: 0.9246547965116279\n",
      "Epoch 26 done! Average Train Loss: 0.2715107276515905, Average Train Accuracy: 0.9250545058139535\n",
      "Epoch 27 done! Average Train Loss: 0.26616263715333716, Average Train Accuracy: 0.9259629360465116\n",
      "Epoch 28 done! Average Train Loss: 0.26632048588159474, Average Train Accuracy: 0.9265079941860465\n",
      "Epoch 29 done! Average Train Loss: 0.26462508469473484, Average Train Accuracy: 0.9263081395348837\n",
      "Finished 30 epochs\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Create a session for the model to run in, and then set up a train loop\n",
    "# to optimize the weights given the mnist data. Optionally, add tensorboard visualization too.\n",
    "nb_train_examples = mnist.train.num_examples\n",
    "batch_size = 128\n",
    "nb_epochs = 30\n",
    "batches_per_epoch = int(math.ceil(nb_train_examples/batch_size))\n",
    "log_period = 250\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 7.1 Initialize your Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Set up tensorboard writer (optional)\n",
    "    train_writer = tf.summary.FileWriter(\"./logs/train\",\n",
    "                                         sess.graph)\n",
    "    for epoch in range(nb_epochs):\n",
    "        epoch_total_loss = 0\n",
    "        epoch_total_accuracy = 0\n",
    "        \n",
    "        for batch in range(batches_per_epoch):\n",
    "            loop_global_step = sess.run(global_step) + 1\n",
    "            batch_inputs, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            # Step 7.2 Get the batch loss, batch accuracy, and run the training op.\n",
    "            # If the log period is up, write summaries to tensorboard.\n",
    "            batch_loss, batch_acc, _ = sess.run([loss, accuracy, train_op], \n",
    "                                         feed_dict={mnist_inputs: batch_inputs, \n",
    "                                                    mnist_labels: batch_labels})\n",
    "            if loop_global_step % log_period == 0:\n",
    "                train_summary = sess.run(summary_op, \n",
    "                                         feed_dict={mnist_inputs: batch_inputs, \n",
    "                                                    mnist_labels: batch_labels})\n",
    "                train_writer.add_summary(train_summary, loop_global_step)\n",
    "                \n",
    "            epoch_total_loss += batch_loss\n",
    "            epoch_total_accuracy += batch_acc\n",
    "        \n",
    "        epoch_average_loss = epoch_total_loss / batches_per_epoch\n",
    "        epoch_average_accuracy = epoch_total_accuracy / batches_per_epoch\n",
    "        print(\"Epoch {} done! Average Train Loss: {}, Average Train Accuracy: {}\".format(epoch, \n",
    "                                                                                 epoch_average_loss, \n",
    "                                                                                 epoch_average_accuracy))\n",
    "    print(\"Finished {} epochs\".format(nb_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
