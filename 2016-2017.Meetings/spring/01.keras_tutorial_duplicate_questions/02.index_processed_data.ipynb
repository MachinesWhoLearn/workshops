{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the processed data we created in the previous notebook.\n",
    "raw_train_lines = pickle.load(open(\"./data/processed/01.processed_train.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'step',\n",
       "  'by',\n",
       "  'step',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'share',\n",
       "  'market',\n",
       "  'in',\n",
       "  'india',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'step',\n",
       "  'by',\n",
       "  'step',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'share',\n",
       "  'market',\n",
       "  '?'],\n",
       " 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first example\n",
    "raw_train_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, each data point consists of two strings and an integer label. Computers don't like dealing with strings directly very much, so we need to convert these strings to lists of integers.\n",
    "\n",
    "The way we do this is: we will assign each string a unique integer ID, and then replace all occurences of the string with that integer ID. In this way, we can encode to the model what the various input strings are. This is called \"indexing\" the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padding_token = \"@@PADDING@@\"\n",
    "oov_token = \"@@UNKOWN@@\"\n",
    "word_indices = {padding_token: 0, oov_token: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [00:02<00:00, 140863.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for train_instance in tqdm(raw_train_lines):\n",
    "    # unpack the tuple into 3 variables\n",
    "    question_1, question_2, label = train_instance\n",
    "\n",
    "    # iterate over the tokens in each question, and add them to the word\n",
    "    # indices if they aren't in there already\n",
    "    for word in question_1:\n",
    "        if word not in word_indices:\n",
    "            # by taking the current length of the dictionary\n",
    "            # to be the index, we can guarantee that each unique word\n",
    "            # will get a unique index.\n",
    "            index = len(word_indices)\n",
    "            word_indices[word] = index\n",
    "\n",
    "    for word in question_2:\n",
    "        if word not in word_indices:\n",
    "            # by taking the current length of the dictionary\n",
    "            # to be the index, we can guarantee that each unique word\n",
    "            # will get a unique index.\n",
    "            index = len(word_indices)\n",
    "            word_indices[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104472"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of unique tokens in our corpus\n",
    "len(word_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert the `raw_train_lines`, which are string representations, to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [00:06<00:00, 64112.93it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_train_lines = []\n",
    "for train_instance in tqdm(raw_train_lines):\n",
    "    # unpack the tuple into 3 variables\n",
    "    question_1, question_2, label = train_instance\n",
    "    \n",
    "    # for each token in question_1 and question_2, replace it with its index\n",
    "    indexed_question_1 = [word_indices[word] for word in question_1]\n",
    "    indexed_question_2 = [word_indices[word] for word in question_2]\n",
    "\n",
    "    indexed_train_lines.append((indexed_question_1, indexed_question_2, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 10, 13, 14],\n",
       " [2, 3, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 14],\n",
       " 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first indexed example, which is the indexed version of \n",
    "# the raw example we printed above.\n",
    "indexed_train_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare the output of the first indexed example with the first raw example, you will see that each word has been assigned a unique index and words that are the same across sentences have the same index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll repackage the lists into a slightly more digestible format for the model. We will have one list of lists (note that each \"question\" now is a list of integers) for all of the question_1's, and one list of lists for all of the question_2's. Then, we'll have a list of labels.\n",
    "\n",
    "These lists should correspond index-wise, so that `label[i]` should correspond to the correct label of the data point with `indexed_question_1s[i]` and `indexed_question_2s[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [00:00<00:00, 941351.69it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_question_1s = []\n",
    "indexed_question_2s = []\n",
    "labels = []\n",
    "\n",
    "for indexed_train_line in tqdm(indexed_train_lines):\n",
    "    # Unpack the tuple into 3 variables\n",
    "    indexed_question_1, indexed_question_2, label = indexed_train_line\n",
    "    \n",
    "    # Now add each of the individual elements of one train instance to their\n",
    "    # separate lists.\n",
    "    indexed_question_1s.append(indexed_question_1)\n",
    "    indexed_question_2s.append(indexed_question_2)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First indexed_question_1s: [2, 3, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 10, 13, 14]\n",
      "First indexed_question_2s: [2, 3, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 14]\n",
      "First label: 0\n"
     ]
    }
   ],
   "source": [
    "# Print the first element from each of the lists, it should be the same as the\n",
    "# first element of the combined dataset above.\n",
    "print(\"First indexed_question_1s: {}\".format(indexed_question_1s[0]))\n",
    "print(\"First indexed_question_2s: {}\".format(indexed_question_2s[0]))\n",
    "print(\"First label: {}\".format(labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like everything matches up! We'll pickle these indexed instances for use when actually training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle the data lists.\n",
    "pickle.dump(indexed_question_1s, open(\"./data/processed/02.indexed_question_1s_train.pkl\", \"wb\"))\n",
    "pickle.dump(indexed_question_2s, open(\"./data/processed/02.indexed_question_2s_train.pkl\", \"wb\"))\n",
    "pickle.dump(labels, open(\"./data/processed/02.labels_train.pkl\", \"wb\"))\n",
    "\n",
    "# Also pickle the word indices\n",
    "pickle.dump(word_indices, open(\"./data/processed/02.word_indices.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
