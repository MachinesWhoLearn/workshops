{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seq2Seq Recurrent Neural Networks in Python\n",
    "\n",
    "## A demo of grapheme to phoneme with LSTMs\n",
    "\n",
    "The applications and code shown in this presentation are from https://github.com/cmusphinx/g2p-seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intuition behind recurrent neural networks (RNNs)\n",
    "\n",
    "## Traditional Neural Networks do not persist information\n",
    "- When we think, we do not read every word independently; their meaning is gleaned from the context of the words that have come before them\n",
    "\n",
    "## RNNs attempt to solve this issue\n",
    "- Neural networks with loops, so information can persist from cell to cell. (image courtesy of Christopher Olah)\n",
    "![RNN](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
    "\n",
    "## Many types and applications of them\n",
    "- These slides won't go over how they work or what types there are, but there is ample literature out there to explain.\n",
    "- [Understanding LSTM networks - Christopher Olah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks - Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [A Tutorial on Deep Learning Part 2: Autoencoders, Convolutional Neural Networks and Recurrent Neural Networks - Quoc Le](https://cs.stanford.edu/~quocle/tutorial2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seq2Seq Encoder-Decoder\n",
    "\n",
    "## Core question - can we condition generated words on some input to get some meaningful response?\n",
    "- Yes! Encoder-decoders are used for machine translation, conversation generation, and image captioning.\n",
    "![Conversation](http://suriyadeepan.github.io/img/seq2seq/seq2seq2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grapheme to Phoneme\n",
    "\n",
    "## Given a word, how do we pronounce it?\n",
    "- Grapheme refers to the orthographic spelling, phoneme is the sounds \n",
    "- for example: `green` is mapped to `G R IY N`\n",
    "\n",
    "## Let's use RNNs to generate a phonemes from graphemes!\n",
    "- this is super useful --- imagine a machine being able to pronounce novel words that it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
